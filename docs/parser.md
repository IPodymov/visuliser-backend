# Парсер данных (Import Manager)

Проект включает в себя инструмент для массового импорта данных из Excel-файлов учебных планов.

## Структура данных

Парсер ожидает следующую структуру директорий в папке `data/`:

```
data/
├── Fit_2023/
│   ├── 03 - ... .xlsx
│   └── ...
├── Fit_2024/
│   └── ...
└── ...
```

- **Год набора**: Определяется из названия папки (например, `Fit_2023` -> 2023).
- **Формат файла**: `.xlsx`

### Обработка листов Excel

1.  **Лист 1 (Информация о программе)**:
    - Считываются метаданные программы: Профиль, Факультет, Вид образования, Уровень образования, Квалификация и т.д.
    - Данные автоматически нормализуются и связываются с соответствующими справочниками (Faculty, Direction и т.д.).
    - Программа идентифицируется по сочетанию направления и профиля.

2.  **Лист 2 (Дисциплины)**:
    - Считывается список дисциплин.
    - Дисциплины сохраняются и связываются с программой.
    - При повторном запуске для существующей программы старые дисциплины удаляются и заменяются новыми из файла (для предотвращения дубликатов).

## Валидация данных

При загрузке программы выполняется валидация:

- **Профиль программы**: Не может быть пустым или равным `"nan"`. При попытке загрузить программу с невалидным профилем возникает ошибка `InvalidProgramError`.

### Пример ошибки валидации

```
InvalidProgramError: Invalid profile value: 'nan'. Profile cannot be 'nan' or empty.
```

## Запуск импорта

### Через командную строку (management command)

Для массовой загрузки из всех папок `data/Fit_*`:

```bash
python manage.py import_all_data
```

Команда:
1.  Сканирует директорию `data/`.
2.  Находит папки, соответствующие паттерну `Fit_YYYY`.
3.  Обрабатывает каждый `.xlsx` файл внутри.
4.  Выводит прогресс и ошибки в консоль.

### Через API (для сотрудников и администраторов)

Загрузка одного файла через HTTP API:

```bash
curl -X POST http://localhost:8000/api/programs/upload/ \
  -H "Cookie: sessionid=<session_id>" \
  -F "file=@/path/to/program.xlsx" \
  -F "year=2025"
```

## Архитектура парсера

Парсер следует принципу **Single Responsibility Principle (SRP)** и разделён на два класса в `programs/services.py`:

### ExcelParser

Отвечает за чтение Excel-файлов и извлечение сырых данных в формате pandas DataFrame или dict.

**Методы:**

- `parse_program_data(file_path)` — парсинг метаданных программы из файла на диске
- `parse_disciplines_data(file_path)` — парсинг дисциплин из файла на диске

### ProgramImporter

Отвечает за бизнес-логику импорта данных в базу, включая создание/поиск справочных сущностей (Faculty, Direction идр.) и сохранение дисциплин.

**Методы:**

- `import_from_file(file_path, year)` — полный цикл импорта файла
- `_get_or_create_dictionary_objects(...)` — создание связанных справочников
- `_save_disciplines(...)` — сохранение списка дисциплин

## Исключения

- **`InvalidProgramError`** — возникает при попытке загрузить программу с невалидными данными
- **`ValueError`** — возникает при ошибках чтения структуры Excel-файла
